{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-RFgu8R-ZwKF",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **Connecting Drive**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7YWks-qszIPr",
    "outputId": "f42c3e4e-0e0a-4e38-8acc-65356ac2db57"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[32m      2\u001b[39m drive.mount(\u001b[33m\"\u001b[39m\u001b[33m/content/drive/\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQq5JvjGaF8q"
   },
   "source": [
    "# **Importing Important Libraries**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "1BxgbUJ6zDnl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NOpxiIAb0Fs5",
    "outputId": "21f46976-7e12-46a2-e2f2-4410ff634af8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Now I am getting angry and I want my damn pho.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Honeslty it didn't taste THAT fresh.)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The potatoes were like rubber and you could te...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The fries were great too.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A great touch.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1\n",
       "5     Now I am getting angry and I want my damn pho.      0\n",
       "6              Honeslty it didn't taste THAT fresh.)      0\n",
       "7  The potatoes were like rubber and you could te...      0\n",
       "8                          The fries were great too.      1\n",
       "9                                     A great touch.      1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Restaurant_Reviews.tsv\", delimiter=\"\\t\", quoting=3)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6GJNU23abM3"
   },
   "source": [
    "# **Data Wrangling**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<ul>\n",
    "<li>Cleaning only the alphabetical data.</li>\n",
    "<li>Making all data lowercase.</li>\n",
    "<li>Removing Stopwords.</li>\n",
    "</ul>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F6Qu6dr12li6",
    "outputId": "5f47ff5b-8acd-494b-e55d-711742aa8080"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ishan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dAaznASw3-s-",
    "outputId": "6e3f1b35-4449-4c98-e349-2c2e2ec35c95"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m corpus = []\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m,\u001b[32m1000\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m   review = \u001b[43mre\u001b[49m.sub(pattern=\u001b[33m'\u001b[39m\u001b[33m[^a-zA-Z]\u001b[39m\u001b[33m'\u001b[39m,repl=\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m,string=data[\u001b[33m'\u001b[39m\u001b[33mReview\u001b[39m\u001b[33m'\u001b[39m][i])\n\u001b[32m      6\u001b[39m   review = review.lower()\n\u001b[32m      7\u001b[39m   review_words = review.split()\n",
      "\u001b[31mNameError\u001b[39m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "for i in range(0,1000):\n",
    "\n",
    "  review = re.sub(pattern='[^a-zA-Z]',repl=' ',string=data['Review'][i])\n",
    "  review = review.lower()\n",
    "  review_words = review.split()\n",
    "  review_words = [ word for word in review_words if not word in set(stopwords.words('english'))]\n",
    "  review = [ps().stem(word) for word in review_words]\n",
    "  review = ' '.join(review)\n",
    "  corpus.append(review)\n",
    "\n",
    "corpus[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "agreP5-48pIH"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeature_extraction\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CountVectorizer\n\u001b[32m      2\u001b[39m cv = CountVectorizer(max_features=\u001b[32m1500\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m X = \u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m)\u001b[49m.toarray()\n\u001b[32m      4\u001b[39m y = data.iloc[: ,\u001b[32m1\u001b[39m].values\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\python\\IBM_SkillsBuild_Internship_Project\\venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\python\\IBM_SkillsBuild_Internship_Project\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1376\u001b[39m, in \u001b[36mCountVectorizer.fit_transform\u001b[39m\u001b[34m(self, raw_documents, y)\u001b[39m\n\u001b[32m   1368\u001b[39m             warnings.warn(\n\u001b[32m   1369\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mUpper case characters found in\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1370\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m vocabulary while \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlowercase\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1371\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m is True. These entries will not\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1372\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m be matched with any documents\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1373\u001b[39m             )\n\u001b[32m   1374\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1376\u001b[39m vocabulary, X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.binary:\n\u001b[32m   1379\u001b[39m     X.data.fill(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\python\\IBM_SkillsBuild_Internship_Project\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1282\u001b[39m, in \u001b[36mCountVectorizer._count_vocab\u001b[39m\u001b[34m(self, raw_documents, fixed_vocab)\u001b[39m\n\u001b[32m   1280\u001b[39m     vocabulary = \u001b[38;5;28mdict\u001b[39m(vocabulary)\n\u001b[32m   1281\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vocabulary:\n\u001b[32m-> \u001b[39m\u001b[32m1282\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1283\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1284\u001b[39m         )\n\u001b[32m   1286\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m indptr[-\u001b[32m1\u001b[39m] > np.iinfo(np.int32).max:  \u001b[38;5;66;03m# = 2**31 - 1\u001b[39;00m\n\u001b[32m   1287\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[31mValueError\u001b[39m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = data.iloc[: ,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iwav6X-W9lyv"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MpY3KyTbQcc"
   },
   "source": [
    "# **Multinomial Naive Baise Classifier**\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "VG8257B4Hk0a",
    "outputId": "e90dcf1d-841d-463b-f863-f860f1bdfbcb"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier =  MultinomialNB()\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5gzAX3eHH9JA",
    "outputId": "6dbacfef-0b51-4171-b394-ed450f9d90af"
   },
   "outputs": [],
   "source": [
    "y_predict = classifier.predict(X_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I7F5svVmK95p",
    "outputId": "9adbec29-d20b-4755-db18-06e12ae7c131"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "score1 = accuracy_score(y_test,y_predict)\n",
    "score2 = precision_score(y_test,y_predict)\n",
    "score3 = recall_score(y_test,y_predict)\n",
    "\n",
    "print(f\"The accuracy score for the model is {score1*100}%\")\n",
    "print(f\"The precision score for the model is {score2*100}%\")\n",
    "print(f\"The recall score for the model is {score3*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DH72uIUK_HIU"
   },
   "source": [
    "<h3>Hyperparameter Tuning</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22XCQWURg6fV",
    "outputId": "d5a4a414-498d-4bc0-ea73-60a7fa8d2093"
   },
   "outputs": [],
   "source": [
    "best_score = 0.0\n",
    "alp = 0.0\n",
    "for i in np.arange (0.1,1.1,0.1):\n",
    "  classifier = MultinomialNB(alpha = i)\n",
    "  classifier.fit(X_train,y_train)\n",
    "  y_predict = classifier.predict(X_test)\n",
    "  score = accuracy_score(y_test,y_predict)\n",
    "  if score > best_score:\n",
    "    best_score = score\n",
    "    alp = i\n",
    "\n",
    "print(\"Best accuracy Score is \"+str(best_score*100)+\" for alpha \"+str(alp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8waibyQR_U0c"
   },
   "source": [
    "<h3>Using the best model as per hyperparameter tuning</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "whUWCjr3_SRq",
    "outputId": "46ab55d6-85c1-4497-84bb-d6fc3e38b1a3"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier =  MultinomialNB(alpha=0.2)\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bu29k0F7_qqB",
    "outputId": "d2383f56-d19c-4a36-f7f6-d12222c27426"
   },
   "outputs": [],
   "source": [
    "y_predict = classifier.predict(X_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iR7LTss9_vZT",
    "outputId": "76f5248d-e313-4daf-ff37-58711acb8ffc"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "score1 = accuracy_score(y_test,y_predict)\n",
    "score2 = precision_score(y_test,y_predict)\n",
    "score3 = recall_score(y_test,y_predict)\n",
    "\n",
    "print(f\"The accuracy score for the model is {score1*100}%\")\n",
    "print(f\"The precision score for the model is {score2*100}%\")\n",
    "print(f\"The recall score for the model is {score3*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vX30jJoj_u29"
   },
   "source": [
    "<h3>Testing the model Against Random Inputs</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yulvo1sCH5vn"
   },
   "outputs": [],
   "source": [
    "def predict_sentiment(sample_review):\n",
    "  sample_review = re.sub(pattern='[^a-zA-Z]',repl=' ',string = sample_review)\n",
    "  sample_review = sample_review.lower()\n",
    "  sample_review_words = sample_review.split()\n",
    "  sample_review_words = [ word for word in sample_review_words if not word in set(stopwords.words('english'))]\n",
    "  final_review = [ps().stem(word) for word in sample_review_words]\n",
    "  final_review = ' '.join(final_review)\n",
    "\n",
    "  temp = cv.transform([final_review]).toarray()\n",
    "  return classifier.predict(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wdln9PtbBa1q",
    "outputId": "893b6715-29c7-4673-a345-bbd64354c27c"
   },
   "outputs": [],
   "source": [
    "sample_review = ['The food is really wonderful',\n",
    "                 'The food is bad and service is also not good',\n",
    "                 'Not tasty and the texture was just nasty',\n",
    "                 'Highly recommended',\n",
    "                 'The worst was the salmon sashimi']\n",
    "i=1\n",
    "for sample in sample_review:\n",
    "  if predict_sentiment(sample):\n",
    "    print(f'The review {i} is Positive')\n",
    "  else:\n",
    "    print(f'The review {i} is Negative')\n",
    "  i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQYTxSypbhVP"
   },
   "source": [
    "# **Logistic Regression**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "0wOPbbmAUKsw",
    "outputId": "7904c759-1e39-43df-c29e-2663f0be3eeb"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "sm = SMOTE(random_state = 2)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v230TjuHUKdW",
    "outputId": "fd40eb54-6b91-4814-b9fc-f64cfa199f24"
   },
   "outputs": [],
   "source": [
    "y_predict = classifier.predict(X_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JH9aOAIqU-o2",
    "outputId": "2e6d0c42-226f-483b-9afb-afec6607e889"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "score1 = accuracy_score(y_test,y_predict)\n",
    "score2 = precision_score(y_test,y_predict)\n",
    "score3 = recall_score(y_test,y_predict)\n",
    "\n",
    "print(f\"The accuracy score for the model is {score1*100}%\")\n",
    "print(f\"The precision score for the model is {score2*100}%\")\n",
    "print(f\"The recall score for the model is {score3*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8UW8eUKQ8qK"
   },
   "source": [
    "<h3>Testing the model against random inputs.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RoyxsPXuRC29"
   },
   "outputs": [],
   "source": [
    "def predict_sentiment(sample_review):\n",
    "  sample_review = re.sub(pattern='[^a-zA-Z]',repl=' ',string = sample_review)\n",
    "  sample_review = sample_review.lower()\n",
    "  sample_review_words = sample_review.split()\n",
    "  sample_review_words = [ word for word in sample_review_words if not word in set(stopwords.words('english'))]\n",
    "  final_review = [ps().stem(word) for word in sample_review_words]\n",
    "  final_review = ' '.join(final_review)\n",
    "\n",
    "  temp = cv.transform([final_review]).toarray()\n",
    "  return classifier.predict(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QPkrFqnYRI8e",
    "outputId": "9d9a7e4a-ad5a-4e3a-c1f4-39648045447f"
   },
   "outputs": [],
   "source": [
    "sample_review = ['The food is really wonderful',\n",
    "                 'The food is bad and service is also not good',\n",
    "                 'Not tasty and the texture was just nasty',\n",
    "                 'Highly recommended',\n",
    "                 'The worst was the salmon sashimi']\n",
    "i=1\n",
    "for sample in sample_review:\n",
    "  if predict_sentiment(sample):\n",
    "    print(f'The review {i} is Positive')\n",
    "  else:\n",
    "    print(f'The review {i} is Negative')\n",
    "  i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJGtS9igbpYo"
   },
   "source": [
    "# **Decision Tree Classifier**\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "xUDjbOIdY8nn",
    "outputId": "da9c105f-7415-41ed-fef8-115334b43750"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion=\"entropy\", max_depth=1)\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3pb-nnw5ZEc9",
    "outputId": "7491f119-69d0-49aa-9501-3835a223506e"
   },
   "outputs": [],
   "source": [
    "y_predict = classifier.predict(X_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IsuO9ILhZETp",
    "outputId": "26fb47b0-0fa1-438e-8192-695a090c8c0b"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "score1 = accuracy_score(y_test,y_predict)\n",
    "score2 = precision_score(y_test,y_predict)\n",
    "score3 = recall_score(y_test,y_predict)\n",
    "\n",
    "print(f\"The accuracy score for the model is {score1*100}%\")\n",
    "print(f\"The precision score for the model is {score2*100}%\")\n",
    "print(f\"The recall score for the model is {score3*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAyHyeLmdt_s"
   },
   "source": [
    "<h3>Hyperparameter Tuning</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qm7DJAmTc7nX",
    "outputId": "fff7d5cf-7bec-4c2e-f782-01e29aef49e2"
   },
   "outputs": [],
   "source": [
    "best_score = 0.0\n",
    "dep = 0\n",
    "for i in range (10,100):\n",
    "  classifier = DecisionTreeClassifier(criterion=\"entropy\", max_depth=i)\n",
    "  classifier.fit(X_train,y_train)\n",
    "  y_predict = classifier.predict(X_test)\n",
    "  score = accuracy_score(y_test,y_predict)\n",
    "  if score > best_score:\n",
    "    best_score = score\n",
    "    dep = i\n",
    "\n",
    "print(\"Best accuracy Score is \"+str(best_score*100)+\" for max_depth \"+str(dep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHZ-FV4yRdv-"
   },
   "source": [
    "<h3>Using the best model as per hyperparameter tuning</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "ZdZ7VrZ4Rc6X",
    "outputId": "f7b7d99f-78f7-4fab-b53d-492f7f3bfead"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion=\"entropy\", max_depth=30)\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6mtL3STXT-eJ",
    "outputId": "9bc4dcec-e1ac-44a9-9acc-b766e0ea01b7"
   },
   "outputs": [],
   "source": [
    "y_predict = classifier.predict(X_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hjDbe1Q4T-Q0",
    "outputId": "aefb5cc3-b30a-4460-dde4-4ec51b5acf81"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "score1 = accuracy_score(y_test,y_predict)\n",
    "score2 = precision_score(y_test,y_predict)\n",
    "score3 = recall_score(y_test,y_predict)\n",
    "\n",
    "print(f\"The accuracy score for the model is {score1*100}%\")\n",
    "print(f\"The precision score for the model is {score2*100}%\")\n",
    "print(f\"The recall score for the model is {score3*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVm9LiVoUKBr"
   },
   "source": [
    "<h3>Testing the model against random inputs.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_gSRJfJVUTT1"
   },
   "outputs": [],
   "source": [
    "def predict_sentiment(sample_review):\n",
    "  sample_review = re.sub(pattern='[^a-zA-Z]',repl=' ',string = sample_review)\n",
    "  sample_review = sample_review.lower()\n",
    "  sample_review_words = sample_review.split()\n",
    "  sample_review_words = [ word for word in sample_review_words if not word in set(stopwords.words('english'))]\n",
    "  final_review = [ps().stem(word) for word in sample_review_words]\n",
    "  final_review = ' '.join(final_review)\n",
    "\n",
    "  temp = cv.transform([final_review]).toarray()\n",
    "  return classifier.predict(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3lvV7PG_UliZ",
    "outputId": "16264e5a-1807-4188-ab9a-d10d30613b9b"
   },
   "outputs": [],
   "source": [
    "sample_review = ['The food is really wonderful',\n",
    "                 'The food is bad and service is also not good',\n",
    "                 'Not tasty and the texture was just nasty',\n",
    "                 'Highly recommended',\n",
    "                 'The worst was the salmon sashimi']\n",
    "i=1\n",
    "for sample in sample_review:\n",
    "  if predict_sentiment(sample):\n",
    "    print(f'The review {i} is Positive')\n",
    "  else:\n",
    "    print(f'The review {i} is Negative')\n",
    "  i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EBvGPrD9a3B"
   },
   "source": [
    "# **Random Forest Classifier**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "nvCe4OkguY4a",
    "outputId": "4aaab4a3-b445-4d94-f079-e76d3c6885c4"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(criterion=\"entropy\")\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zMMz134wvTZB",
    "outputId": "9f1304fc-75d7-485f-8ca8-c2b132170a86"
   },
   "outputs": [],
   "source": [
    "y_predict = classifier.predict(X_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xQ41oAlNvUfT",
    "outputId": "2666a443-1d0c-4e8d-fb77-1ea3618f5783"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "score1 = accuracy_score(y_test,y_predict)\n",
    "score2 = precision_score(y_test,y_predict)\n",
    "score3 = recall_score(y_test,y_predict)\n",
    "\n",
    "print(f\"The accuracy score for the model is {score1*100}%\")\n",
    "print(f\"The precision score for the model is {score2*100}%\")\n",
    "print(f\"The recall score for the model is {score3*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWKHTf03ghdF"
   },
   "source": [
    "<h3>Hyperparameter tuning</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yOY1nhpPv1DY",
    "outputId": "fedcb14e-8498-4193-c6e1-21414b9dcd46"
   },
   "outputs": [],
   "source": [
    "best_score = 0.0\n",
    "dep = 0\n",
    "for i in range (1,50):\n",
    "  classifier = RandomForestClassifier(criterion=\"entropy\", max_depth=i)\n",
    "  classifier.fit(X_train,y_train)\n",
    "  y_predict = classifier.predict(X_test)\n",
    "  score = accuracy_score(y_test,y_predict)\n",
    "  if score > best_score:\n",
    "    best_score = score\n",
    "    dep = i\n",
    "\n",
    "print(\"Best accuracy Score is \"+str(best_score*100)+\" for max_depth \"+str(dep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23Ww6B9bgtxD"
   },
   "source": [
    "<h3>Using the best model as per hyperparameter tuning.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "7bsuMI5wg9To",
    "outputId": "174dd976-1b08-4c79-eab7-02d27ce31e97"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(criterion=\"entropy\", max_depth=dep)\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SwxlDupeg8_O",
    "outputId": "96a40ff1-8f3b-4d1e-cf8b-4736c6ba7ee0"
   },
   "outputs": [],
   "source": [
    "y_predict = classifier.predict(X_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vUOf_5uRg8VR",
    "outputId": "bd05b293-7f67-4ced-f608-264223d5d784"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "score1 = accuracy_score(y_test,y_predict)\n",
    "score2 = precision_score(y_test,y_predict)\n",
    "score3 = recall_score(y_test,y_predict)\n",
    "\n",
    "print(f\"The accuracy score for the model is {score1*100}%\")\n",
    "print(f\"The precision score for the model is {score2*100}%\")\n",
    "print(f\"The recall score for the model is {score3*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRWVDC2ljI88"
   },
   "source": [
    "<h3>Testing the model against random input.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uWJ1Ny0ZjR6x"
   },
   "outputs": [],
   "source": [
    "def predict_sentiment(sample_review):\n",
    "  sample_review = re.sub(pattern='[^a-zA-Z]',repl=' ',string = sample_review)\n",
    "  sample_review = sample_review.lower()\n",
    "  sample_review_words = sample_review.split()\n",
    "  sample_review_words = [ word for word in sample_review_words if not word in set(stopwords.words('english'))]\n",
    "  final_review = [ps().stem(word) for word in sample_review_words]\n",
    "  final_review = ' '.join(final_review)\n",
    "\n",
    "  temp = cv.transform([final_review]).toarray()\n",
    "  return classifier.predict(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gkIppSWSkU_O",
    "outputId": "e047ae3d-0d5d-4a9c-bbfd-50c5c8f0afe9"
   },
   "outputs": [],
   "source": [
    "sample_review = ['The food is really wonderful',\n",
    "                 'The food is bad and service is also not good',\n",
    "                 'Not tasty and the texture was just nasty',\n",
    "                 'Highly recommended',\n",
    "                 'The worst was the salmon sashimi']\n",
    "i=1\n",
    "for sample in sample_review:\n",
    "  if predict_sentiment(sample):\n",
    "    print(f'The review {i} is Positive')\n",
    "  else:\n",
    "    print(f'The review {i} is Negative')\n",
    "  i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D41SY8vG9i73"
   },
   "source": [
    "# **Extra Trees Classifier**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "yEk-lpRlxMib",
    "outputId": "6d9f609a-3b33-48a0-a032-51e8565117be"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "classifier = ExtraTreesClassifier()\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gasgdWPBxVqh",
    "outputId": "07636fd9-6e7b-4315-f964-5e4bd7483b4b"
   },
   "outputs": [],
   "source": [
    "y_predict = classifier.predict(X_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IYTSjEDYxYCU",
    "outputId": "2ce3d4f4-f250-47f6-d539-2d3234f20f14"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "score1 = accuracy_score(y_test,y_predict)\n",
    "score2 = precision_score(y_test,y_predict)\n",
    "score3 = recall_score(y_test,y_predict)\n",
    "\n",
    "print(f\"The accuracy score for the model is {score1*100}%\")\n",
    "print(f\"The precision score for the model is {score2*100}%\")\n",
    "print(f\"The recall score for the model is {score3*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0B6e1hCEkeGc"
   },
   "source": [
    "<h3>Hyperparameter Tuning</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1dlyAHGxlV-",
    "outputId": "d47d3489-6424-4b2f-ae96-8df526297cf0"
   },
   "outputs": [],
   "source": [
    "best_score = 0.0\n",
    "dep = 0\n",
    "for i in range (1,50):\n",
    "  classifier = ExtraTreesClassifier(criterion=\"entropy\", max_depth=i)\n",
    "  classifier.fit(X_train,y_train)\n",
    "  y_predict = classifier.predict(X_test)\n",
    "  score = accuracy_score(y_test,y_predict)\n",
    "  if score > best_score:\n",
    "    best_score = score\n",
    "    dep = i\n",
    "\n",
    "print(\"Best accuracy Score is \"+str(best_score*100)+\" for max_depth \"+str(dep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "45M9YkZNsyfP",
    "outputId": "2647320d-0acd-4f6d-e869-e6ea00e93eb0"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "classifier = ExtraTreesClassifier(criterion=\"entropy\", max_depth=dep)\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jzUyFg6dsyK_",
    "outputId": "4544f7c1-c590-4afc-bde8-1b6b2b77694b"
   },
   "outputs": [],
   "source": [
    "y_predict = classifier.predict(X_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t1BcV33Ssx9W",
    "outputId": "069a0246-cb30-4889-e5ae-eefd3033021a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m precision_score\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m recall_score\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m score1 = accuracy_score(\u001b[43my_test\u001b[49m,y_predict)\n\u001b[32m      6\u001b[39m score2 = precision_score(y_test,y_predict)\n\u001b[32m      7\u001b[39m score3 = recall_score(y_test,y_predict)\n",
      "\u001b[31mNameError\u001b[39m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "score1 = accuracy_score(y_test,y_predict)\n",
    "score2 = precision_score(y_test,y_predict)\n",
    "score3 = recall_score(y_test,y_predict)\n",
    "\n",
    "print(f\"The accuracy score for the model is {score1*100}%\")\n",
    "print(f\"The precision score for the model is {score2*100}%\")\n",
    "print(f\"The recall score for the model is {score3*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "be_05yfKlAZ9"
   },
   "source": [
    "<h3>Testing the model against random input</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VL2KR-bKlJYC"
   },
   "outputs": [],
   "source": [
    "def predict_sentiment(sample_review):\n",
    "  sample_review = re.sub(pattern='[^a-zA-Z]',repl=' ',string = sample_review)\n",
    "  sample_review = sample_review.lower()\n",
    "  sample_review_words = sample_review.split()\n",
    "  sample_review_words = [ word for word in sample_review_words if not word in set(stopwords.words('english'))]\n",
    "  final_review = [ps().stem(word) for word in sample_review_words]\n",
    "  final_review = ' '.join(final_review)\n",
    "\n",
    "  temp = cv.transform([final_review]).toarray()\n",
    "  return classifier.predict(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SLe-goJ2meXO",
    "outputId": "89c45166-a835-4220-9762-3877c0a19443"
   },
   "outputs": [],
   "source": [
    "sample_review = ['The food is really wonderful',\n",
    "                 'The food is bad and service is also not good',\n",
    "                 'Not tasty and the texture was just nasty',\n",
    "                 'Highly recommended',\n",
    "                 'The worst was the salmon sashimi']\n",
    "i=1\n",
    "for sample in sample_review:\n",
    "  if predict_sentiment(sample):\n",
    "    print(f'The review {i} is Positive')\n",
    "  else:\n",
    "    print(f'The review {i} is Negative')\n",
    "  i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKf5Xg3N88UB"
   },
   "source": [
    "# **KNeighborsClassifier**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "ANr503aEd6ak",
    "outputId": "20d8170e-2882-4f4e-b0fc-1434331e44c8"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier()\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33hjhCq2eEPJ",
    "outputId": "d2d6019f-ebfe-4e49-a217-2f239063404c"
   },
   "outputs": [],
   "source": [
    "y_predict = classifier.predict(X_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tcmj0Jj4eHPg",
    "outputId": "fa775339-0d48-4ea4-e69f-526476a64c2c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "score1 = accuracy_score(y_test,y_predict)\n",
    "score2 = precision_score(y_test,y_predict)\n",
    "score3 = recall_score(y_test,y_predict)\n",
    "\n",
    "print(f\"The accuracy score for the model is {score1*100}%\")\n",
    "print(f\"The precision score for the model is {score2*100}%\")\n",
    "print(f\"The recall score for the model is {score3*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghj6oixEeTUU"
   },
   "source": [
    "<h3>Hyperparameter Tuning</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cjk24wvdeP-G",
    "outputId": "47c6f120-d492-43cf-b496-da3bd730a718"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KNeighborsClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m n = \u001b[32m0\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (\u001b[32m1\u001b[39m,\u001b[32m100\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m   classifier = \u001b[43mKNeighborsClassifier\u001b[49m(n_neighbors=i)\n\u001b[32m      5\u001b[39m   classifier.fit(X_train,y_train)\n\u001b[32m      6\u001b[39m   y_predict = classifier.predict(X_test)\n",
      "\u001b[31mNameError\u001b[39m: name 'KNeighborsClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "best_score = 0.0\n",
    "n = 0\n",
    "for i in range (1,100):\n",
    "  classifier = KNeighborsClassifier(n_neighbors=i)\n",
    "  classifier.fit(X_train,y_train)\n",
    "  y_predict = classifier.predict(X_test)\n",
    "  score = accuracy_score(y_test,y_predict)\n",
    "  if score > best_score:\n",
    "    best_score = score\n",
    "    n = i\n",
    "\n",
    "print(\"Best accuracy Score is \"+str(best_score*100)+\" for neighbours \"+str(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srR1xMzWbFCo"
   },
   "source": [
    "<h3>Using the best model as per hyperparameter tuning</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "73b5QkvqbNcL",
    "outputId": "ce679895-1a8a-427d-b1d1-dfaa5cb2bb1d"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=n)\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tty_gaylb90Z",
    "outputId": "ef2f67b0-ec0e-4489-e0d0-3ffef94a03c9"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m y_predict = \u001b[43mclassifier\u001b[49m.predict(X_test)\n\u001b[32m      2\u001b[39m y_predict\n",
      "\u001b[31mNameError\u001b[39m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "y_predict = classifier.predict(X_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-uJNhAJb9on",
    "outputId": "34aae41b-dd65-477c-b768-f81150a96e7e"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "score1 = accuracy_score(y_test,y_predict)\n",
    "score2 = precision_score(y_test,y_predict)\n",
    "score3 = recall_score(y_test,y_predict)\n",
    "\n",
    "print(f\"The accuracy score for the model is {score1*100}%\")\n",
    "print(f\"The precision score for the model is {score2*100}%\")\n",
    "print(f\"The recall score for the model is {score3*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUelUI1tcuNf"
   },
   "source": [
    "<h3> Testing the model against random inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_nXBVwy9cnLu"
   },
   "outputs": [],
   "source": [
    "def predict_sentiment(sample_review):\n",
    "  sample_review = re.sub(pattern='[^a-zA-Z]',repl=' ',string = sample_review)\n",
    "  sample_review = sample_review.lower()\n",
    "  sample_review_words = sample_review.split()\n",
    "  sample_review_words = [ word for word in sample_review_words if not word in set(stopwords.words('english'))]\n",
    "  final_review = [ps().stem(word) for word in sample_review_words]\n",
    "  final_review = ' '.join(final_review)\n",
    "\n",
    "  temp = cv.transform([final_review]).toarray()\n",
    "  return classifier.predict(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zR2zyPS3coT7",
    "outputId": "7399fff9-b6e7-40a0-b8d6-4534fd0dff58"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m i=\u001b[32m1\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m sample_review:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpredict_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThe review \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is Positive\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     10\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mpredict_sentiment\u001b[39m\u001b[34m(sample_review)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict_sentiment\u001b[39m(sample_review):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m   sample_review = \u001b[43mre\u001b[49m.sub(pattern=\u001b[33m'\u001b[39m\u001b[33m[^a-zA-Z]\u001b[39m\u001b[33m'\u001b[39m,repl=\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m,string = sample_review)\n\u001b[32m      3\u001b[39m   sample_review = sample_review.lower()\n\u001b[32m      4\u001b[39m   sample_review_words = sample_review.split()\n",
      "\u001b[31mNameError\u001b[39m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "sample_review = ['The food is really wonderful',\n",
    "                 'The food is bad and service is also not good',\n",
    "                 'Not tasty and the texture was just nasty',\n",
    "                 'Highly recommended',\n",
    "                 'The worst was the salmon sashimi']\n",
    "i=1\n",
    "for sample in sample_review:\n",
    "  if predict_sentiment(sample):\n",
    "    print(f'The review {i} is Positive')\n",
    "  else:\n",
    "    print(f'The review {i} is Negative')\n",
    "  i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNvcL4UA9Nsp"
   },
   "source": [
    "# **Support Vector Classification (SVC)**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "cyReS5bpet6V",
    "outputId": "32338988-7d59-407a-ccfb-2875fb80fb6c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msvm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SVC\n\u001b[32m      2\u001b[39m classifier = SVC(kernel=\u001b[33m'\u001b[39m\u001b[33msigmoid\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m classifier.fit(\u001b[43mX_train\u001b[49m,y_train)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel='sigmoid')\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zjwwRMt3fGZB",
    "outputId": "69c2b556-db6f-4bbc-d8d2-10614340480b"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m y_predict = classifier.predict(\u001b[43mX_test\u001b[49m)\n\u001b[32m      2\u001b[39m y_predict\n",
      "\u001b[31mNameError\u001b[39m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "y_predict = classifier.predict(X_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "758k96AWfJ2h",
    "outputId": "b2666ba5-4a8b-4b7c-fc60-a89300561d91"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m precision_score\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m recall_score\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m score1 = accuracy_score(\u001b[43my_test\u001b[49m,y_predict)\n\u001b[32m      6\u001b[39m score2 = precision_score(y_test,y_predict)\n\u001b[32m      7\u001b[39m score3 = recall_score(y_test,y_predict)\n",
      "\u001b[31mNameError\u001b[39m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "score1 = accuracy_score(y_test,y_predict)\n",
    "score2 = precision_score(y_test,y_predict)\n",
    "score3 = recall_score(y_test,y_predict)\n",
    "\n",
    "print(f\"The accuracy score for the model is {score1*100}%\")\n",
    "print(f\"The precision score for the model is {score2*100}%\")\n",
    "print(f\"The recall score for the model is {score3*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRY3OMowejKP"
   },
   "source": [
    "<h3>Hyperparameter Tuning</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bLE3V8fhgkZs",
    "outputId": "fd324d79-bc70-4753-edbc-7230201678a0"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (\u001b[32m0\u001b[39m,\u001b[32m100\u001b[39m):\n\u001b[32m      4\u001b[39m   classifier = SVC(kernel=\u001b[33m'\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m'\u001b[39m,gamma=i)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m   classifier.fit(\u001b[43mX_train\u001b[49m,y_train)\n\u001b[32m      6\u001b[39m   y_predict = classifier.predict(X_test)\n\u001b[32m      7\u001b[39m   score = accuracy_score(y_test,y_predict)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "best_score = 0.0\n",
    "g = 0\n",
    "for i in range (0,100):\n",
    "  classifier = SVC(kernel='linear',gamma=i)\n",
    "  classifier.fit(X_train,y_train)\n",
    "  y_predict = classifier.predict(X_test)\n",
    "  score = accuracy_score(y_test,y_predict)\n",
    "  if score > best_score:\n",
    "    best_score = score\n",
    "    g = i\n",
    "\n",
    "print(\"Best accuracy Score is \"+str(best_score*100)+\" for neighbours \"+str(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4ocW1hcfTJK"
   },
   "source": [
    "*Note : The best model is before we do hyperparameter tuning so we will use the same model before the tuning.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dA-XR9cHfu_E"
   },
   "source": [
    "<h3>Testing the model against random inputs.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YXe8-fAffLu4"
   },
   "outputs": [],
   "source": [
    "def predict_sentiment(sample_review):\n",
    "  sample_review = re.sub(pattern='[^a-zA-Z]',repl=' ',string = sample_review)\n",
    "  sample_review = sample_review.lower()\n",
    "  sample_review_words = sample_review.split()\n",
    "  sample_review_words = [ word for word in sample_review_words if not word in set(stopwords.words('english'))]\n",
    "  final_review = [ps().stem(word) for word in sample_review_words]\n",
    "  final_review = ' '.join(final_review)\n",
    "\n",
    "  temp = cv.transform([final_review]).toarray()\n",
    "  return classifier.predict(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "80a2NO0Ufq7_",
    "outputId": "f022e823-7142-495c-89e1-3a8455acc1d2"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m i=\u001b[32m1\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m sample_review:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpredict_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThe review \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is Positive\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     10\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mpredict_sentiment\u001b[39m\u001b[34m(sample_review)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict_sentiment\u001b[39m(sample_review):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m   sample_review = \u001b[43mre\u001b[49m.sub(pattern=\u001b[33m'\u001b[39m\u001b[33m[^a-zA-Z]\u001b[39m\u001b[33m'\u001b[39m,repl=\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m,string = sample_review)\n\u001b[32m      3\u001b[39m   sample_review = sample_review.lower()\n\u001b[32m      4\u001b[39m   sample_review_words = sample_review.split()\n",
      "\u001b[31mNameError\u001b[39m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "sample_review = ['The food is really wonderful',\n",
    "                 'The food is bad and service is also not good',\n",
    "                 'Not tasty and the texture was just nasty',\n",
    "                 'Highly recommended',\n",
    "                 'The worst was the salmon sashimi']\n",
    "i=1\n",
    "for sample in sample_review:\n",
    "  if predict_sentiment(sample):\n",
    "    print(f'The review {i} is Positive')\n",
    "  else:\n",
    "    print(f'The review {i} is Negative')\n",
    "  i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bSXAHZk0t5X_"
   },
   "source": [
    "# **Conclusion**\n",
    "*   Extra Trees Classifier Algorithm is the best algorithm amongst all the algorithm used for this dataset with the highest accuracy score of 81%\n",
    "* KNeighbours Classifier Algorithm is the worst algorithm amongst all\n",
    "the algorithm used for this dataset with the lowest accuracy score of 67.5%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# After training your model\n",
    "with open('sentiment_model.pkl', 'wb') as file:\n",
    "    pickle.dump(classifier, file)  # `classifier` is your model object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tfidf_vectorizer.pkl', 'wb') as file:\n",
    "    pickle.dump(tfidf, file)  # `tfidf` is your fitted vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Sample training data (use your own dataset)\n",
    "corpus = [\n",
    "    'I love this food',\n",
    "    'This restaurant is terrible',\n",
    "    'Amazing experience',\n",
    "    'Worst service ever'\n",
    "]\n",
    "\n",
    "# 1. Create and fit the vectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(corpus)  # This trains the TF-IDF\n",
    "\n",
    "# 2. Now save it using pickle\n",
    "import pickle\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as file:\n",
    "    pickle.dump(tfidf, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tfidf_vectorizer.pkl', 'wb') as file:\n",
    "    pickle.dump(tfidf, file)  # `tfidf` is your fitted vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Sample training data (use your own dataset)\n",
    "corpus = [\n",
    "    'I love this food',\n",
    "    'This restaurant is terrible',\n",
    "    'Amazing experience',\n",
    "    'Worst service ever'\n",
    "]\n",
    "\n",
    "# 1. Create and fit the vectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(corpus)  # This trains the TF-IDF\n",
    "\n",
    "# 2. Now save it using pickle\n",
    "import pickle\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as file:\n",
    "    pickle.dump(tfidf, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2683470225.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpython train_model.py\u001b[39m\n           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python train_model.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file 'C:\\\\Users\\\\ishan\\\\OneDrive\\\\Desktop\\\\python\\\\IBM_SkillsBuild_Internship_Project\\\\train_model.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python train_model.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3662748302.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpython train_model.py\u001b[39m\n           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python train_model.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOKZGk09kX7AqLrTRzqYgSP",
   "include_colab_link": true,
   "mount_file_id": "1DDKTgxNLpTyRjXjImg0gqEJHiWX69ABR",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
